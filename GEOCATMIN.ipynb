{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ac3112b-cd5f-4310-b731-00b135581e27",
   "metadata": {},
   "source": [
    "## MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166a0e85-8205-4aa6-a03b-71652f37c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.validation import make_valid\n",
    "import rasterio\n",
    "from rasterio.features import shapes\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4564cb0-47c4-4054-8391-1f7e71c171b3",
   "metadata": {},
   "source": [
    "## HYDROGEOLOGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78509c14-a466-4514-b395-42f1395e6ef3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = \"GEOCATMIN/commondata\"\n",
    "directories = [os.path.join(root_dir, d) for d in os.listdir(root_dir)\n",
    "               if os.path.isdir(os.path.join(root_dir, d)) and not any(s in d for s in [\"shp\", \"raster\"])]\n",
    "\n",
    "shp_paths = []\n",
    "for directory in directories:\n",
    "    shp_paths.extend([\n",
    "        os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(\".shp\")\n",
    "    ])\n",
    "    \n",
    "Hydrogeologic_units = pd.concat([gpd.read_file(p) for p in shp_paths], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad311e0c-bf04-48eb-ad19-51b9de2937e9",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(shp_paths)\n",
    "#print(Hydrogeologic_units)\n",
    "#print(pd.unique(Hydrogeologic_units[\"NAME\"]))\n",
    "#Hydrogeologic_units[\"NAME\"] = Hydrogeologic_units[\"NAME\"].str.strip()\n",
    "#print(pd.unique(Hydrogeologic_units[\"NAME\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81cddf71-3c2b-4a39-9f50-a9dd4b4bad99",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    \"Kis-a\": \"Kis-ar\",\n",
    "    \"Js-l\": \"Js-la\",\n",
    "    \"Jm-p\": \"Jm-pu\",\n",
    "    \"Qp-b/c-anda\": \"Q-br2\",\n",
    "    \"NQ-b-and\": \"N-br2\",\n",
    "    \"NP-cbc-gnmg\": \"Js-la\",\n",
    "    \"Jms-p\": \"Jms-pu\",\n",
    "    \"Peo-h/t\": \"Peo-hu/t\",\n",
    "    \"Js-g\": \"Js-gr\",\n",
    "    \"Q-la\": \"Qpl-la\",\n",
    "    \"Peo-h/qu\": \"Peo-hu/qu\",\n",
    "    \"Peo-h/h\": \"Peo-hu/h\",\n",
    "    \"N-and\": \"Js-la\",\n",
    "    \"Nmp-ch-da\": \"N-da\",\n",
    "    \"\\tPeo-hu/h\": \"Peo-hu/h\",\n",
    "    \"Nm-na/da\": \"N-da\",\n",
    "    \"Nm-ta/da\": \"N-da\",\n",
    "    \"Qp-b/am-tcri\": \"Q-br1\",\n",
    "    \"NQ-b-tb\": \"Q-br1\"\n",
    "}\n",
    "Hydrogeologic_units[\"NAME\"] = Hydrogeologic_units[\"NAME\"].replace(replacements)\n",
    "Hydrogeologic_units.loc[Hydrogeologic_units[\"NAME_2\"] == \"PN-o\", \"NAME\"] = \"PN-o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaa55421-6c27-4f30-92cf-c300420bfe63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AREA', 'PERIMETER', 'GEOLUTMM_I', 'CODI', 'NAME', 'DESCRIP', 'HOJA', 'CODI_A', 'NAME_A', 'DESCRIP_A', 'UNIDAD', 'Shape_Leng', 'Shape_Area', 'area_1', 'NAME_2', 'CODI_1', 'Hidro_1', 'Hidro_2', 'Vulnerabil', 'geometry', 'Min', 'Max', 'Prom']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karles\\AppData\\Local\\Temp\\ipykernel_3908\\2454409418.py:15: RuntimeWarning: Mean of empty slice\n",
      "  promedios = [np.nanmean(paired_vals[i:i+2]) for i in range(0, len(paired_vals), 2)]\n",
      "C:\\Users\\Karles\\AppData\\Local\\Temp\\ipykernel_3908\\2454409418.py:16: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(unique_vals + promedios)\n"
     ]
    }
   ],
   "source": [
    "litologia = pd.read_excel(\"GEOCATMIN/resultados.xlsx\", sheet_name=5)\n",
    "nC = litologia.shape[1]\n",
    "\n",
    "def calc_min(row):\n",
    "    valores = row.iloc[2:nC]\n",
    "    return valores.dropna().min() if not valores.dropna().empty else np.nan\n",
    "\n",
    "def calc_max(row):\n",
    "    valores = row.iloc[2:nC]\n",
    "    return valores.dropna().max() if not valores.dropna().empty else np.nan\n",
    "\n",
    "def calc_prom(row):\n",
    "    unique_vals = row.iloc[2:4].dropna().tolist()\n",
    "    paired_vals = row.iloc[4:nC]\n",
    "    promedios = [np.nanmean(paired_vals[i:i+2]) for i in range(0, len(paired_vals), 2)]\n",
    "    return np.nanmean(unique_vals + promedios)\n",
    "\n",
    "litologia[\"Min\"] = litologia.apply(calc_min, axis=1)\n",
    "litologia[\"Max\"] = litologia.apply(calc_max, axis=1)\n",
    "litologia[\"Prom\"] = litologia.apply(calc_prom, axis=1)\n",
    "litologia = litologia[[\"Formación geológica\", \"Min\", \"Max\", \"Prom\"]]\n",
    "litologia.rename(columns={\"Formación geológica\": \"NAME\"}, inplace=True)\n",
    "\n",
    "Hydrogeologic_units_join = Hydrogeologic_units.merge(litologia, on=\"NAME\", how=\"left\")\n",
    "#print(list(Hydrogeologic_units_join.columns))\n",
    "Hydrogeologic_units_join = Hydrogeologic_units_join[[\"NAME\", \"Min\", \"Max\", \"Prom\", \"geometry\"]]\n",
    "Hydrogeologic_units_join[\"geometry\"] = Hydrogeologic_units_join[\"geometry\"].apply(make_valid)\n",
    "\n",
    "Hydrogeologic_units_join.to_file(\"1.PRODUCTOS/Hydrogeologic_units_join.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c844ff-d313-4682-96b4-4270cdf76afc",
   "metadata": {},
   "source": [
    "## MAPSWAT-SOIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f1d42cbd-faa5-46ba-8c50-8ac864c7ad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "Soil_raster_MAPSWAT_path = \"MAPSWAT/MapSWAT/SWAT_INPUT_MAPS/SOIL/SOIL.b1.tif\"\n",
    "Soil_MAPSWAT_properties = pd.read_csv(\"MAPSWAT/MapSWAT/SWAT_INPUT_MAPS/SOIL/DSOLMap_usersoil.csv\")\n",
    "#tmp2 = pd.read_csv(\"MAPSWAT/MapSWAT/SWAT_INPUT_MAPS/SOIL/DSOLMap_taxonomy.csv\")\n",
    "#tmp1.columns.values[0] = tmp2.columns.values[0] = \"SOILID\"\n",
    "#tmp1.columns.values[0] = \"SOILID\"\n",
    "#Soil_properties = tmp1.merge(tmp2, on = \"SOILID\", how = \"left\")\n",
    "#print(list(Soil_properties.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0b01cb14-7ec8-448c-b33e-30a447b42511",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(Soil_raster_MAPSWAT_path) as src:\n",
    "    image = src.read(1)\n",
    "    mask = image != src.nodata\n",
    "    transform = src.transform\n",
    "\n",
    "    results = (\n",
    "        {\"properties\": {\"OBJECTID\": v}, \"geometry\": s}\n",
    "        for s, v in shapes(image, mask=mask, transform=transform)\n",
    "    )\n",
    "\n",
    "Soil_shp_MAPSWAT = gpd.GeoDataFrame.from_features(results)\n",
    "Soil_shp_MAPSWAT.crs = src.crs\n",
    "Soil_shp_MAPSWAT = Soil_shp_MAPSWAT.dissolve(by=\"OBJECTID\")\n",
    "Soil_shp_MAPSWAT = Soil_shp_MAPSWAT.merge(Soil_MAPSWAT_properties, on = \"OBJECTID\", how = \"left\")\n",
    "\n",
    "Soil_shp_MAPSWAT.to_file(\"1.PRODUCTOS/SOIL_MAPSWAT.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8574651-ab71-467b-86cb-4551f89832f4",
   "metadata": {},
   "source": [
    "## MERGING PRODUCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e02b8ceb-5d3d-4f9b-b4f3-3e7d3ad26d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOIL_MAPSWAT = gpd.read_file(\"1.PRODUCTOS/SOIL_MAPSWAT.shp\")\n",
    "#Hydrogeologic_units_join = gpd.read_file(\"1.PRODUCTOS/Hydrogeologic_units_join.shp\")\n",
    "#Hydrogeologic_units_join_dis = Hydrogeologic_units_join.dissolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d10c178b-eaec-4fec-a0b3-9363f7f578f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAPSWAT_Hydrogeologic_inte = gpd.overlay(SOIL_MAPSWAT, Hydrogeologic_units_join, how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8a03cfeb-7b8e-4051-98bd-f6c33aa6d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAPSWAT_Hydrogeologic_diff = gpd.overlay(SOIL_MAPSWAT, Hydrogeologic_units_join_dis, how='difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "58a2508a-c25d-481f-99ae-ed939c2ac41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOIL_map = gpd.GeoDataFrame(pd.concat([MAPSWAT_Hydrogeologic_inte, MAPSWAT_Hydrogeologic_diff], ignore_index=True), crs=SOIL_MAPSWAT.crs)\n",
    "#SOIL_map[\"OBJECTID\"] = range(1, len(SOIL_map) + 1)\n",
    "#SOIL_map[\"SNAM\"] = SOIL_map[\"SNAM\"] + '-' + SOIL_map[\"NAME\"]\n",
    "#SOIL_map.to_file(\"1.PRODUCTOS/SOIL_map.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc93745-f0b7-4f89-b488-42fe197b48f3",
   "metadata": {},
   "source": [
    "#### Equation 1\n",
    "$Q_{soil} = - K(h)\\times \\frac{dh}{dz} - K(h)$\n",
    "\n",
    "For saturated conditions\n",
    "\n",
    "$\\frac{dh}{dz} = 0$\n",
    "\n",
    "Then, we can assume that K values from Hydrogeologic must be equal to the sum of K values form MAPSWAT by a constant \"m\"\n",
    "\n",
    "$K_{hydrogeologic} = r\\times\\sum{ K_{MAPSWAT-layer}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c860973-37fb-4d55-9d2c-45c500aed1cd",
   "metadata": {},
   "source": [
    "#### Equation 2\n",
    "$K_{MAPSWAT} = \\frac{e}{\\sum{\\tfrac{e_i}{K_{MAPSWAT_i}}}}$\n",
    "\n",
    "Assuming the next relationship\n",
    "\n",
    "$\\tfrac{K_{Hydrogeologic}}{K_{MAPSWAT}} = r$\n",
    "\n",
    "Then \n",
    "\n",
    "$\\tfrac{K_{Hydrogeologic_i}}{K_{MAPSWAT_i}} = r$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c21bf059-ce03-4912-a870-82300e45a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOIL_map = gpd.read_file(\"1.PRODUCTOS/SOIL_map.shp\")\n",
    "\n",
    "# 3) Preparar tres copias sin eliminar aún nada\n",
    "SOIL_map_min  = SOIL_map.copy()\n",
    "SOIL_map_max  = SOIL_map.copy()\n",
    "SOIL_map_prom = SOIL_map.copy()\n",
    "\n",
    "sol_cols = [atri for atri in SOIL_map.columns if atri.startswith('SOL_K')]\n",
    "hydrogeological_observations = SOIL_map['Min'].notna()\n",
    "\n",
    "for idx, row in SOIL_map[hydrogeological_observations].iterrows():\n",
    "    vals = row[sol_cols]\n",
    "    SOL_K_MAPSWAT = vals.sum()\n",
    "    r_min  = row['Min'] / SOL_K_MAPSWAT\n",
    "    r_max  = row['Max'] / SOL_K_MAPSWAT\n",
    "    r_prom = row['Prom'] / SOL_K_MAPSWAT\n",
    "    \n",
    "    SOIL_map_min.loc[idx, vals.index] = row[vals.index] * r_min\n",
    "    SOIL_map_max.loc[idx, vals.index] = row[vals.index] * r_max\n",
    "    SOIL_map_prom.loc[idx, vals.index] = row[vals.index] * r_prom\n",
    "\n",
    "SOIL_map_min = SOIL_map_min.drop(columns = ['NAME','Min','Max','Prom'])\n",
    "SOIL_map_max = SOIL_map_max.drop(columns = ['NAME','Min','Max','Prom'])\n",
    "SOIL_map_prom = SOIL_map_prom.drop(columns = ['NAME','Min','Max','Prom'])\n",
    "\n",
    "SOIL_map_min.to_file(\"1.PRODUCTOS/SOIL_map_min_v1.shp\")\n",
    "SOIL_map_max.to_file(\"1.PRODUCTOS/SOIL_map_max_v1.shp\")\n",
    "SOIL_map_prom.to_file(\"1.PRODUCTOS/SOIL_map_prom_v1.shp\")\n",
    "\n",
    "SOIL_map_min_table  = SOIL_map_min.drop(columns='geometry')\n",
    "SOIL_map_max_table  = SOIL_map_max.drop(columns='geometry')\n",
    "SOIL_map_prom_table = SOIL_map_prom.drop(columns='geometry')\n",
    "\n",
    "SOIL_map_min_table.to_csv(\"1.PRODUCTOS/SOIL_map_min_v1.csv\", index=False)\n",
    "SOIL_map_max_table.to_csv(\"1.PRODUCTOS/SOIL_map_max_v1.csv\", index=False)\n",
    "SOIL_map_prom_table.to_csv(\"1.PRODUCTOS/SOIL_map_prom_v1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "075323d7-654f-41a0-8e3f-566e7961ac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOIL_map = gpd.read_file(\"1.PRODUCTOS/SOIL_map.shp\")\n",
    "\n",
    "# 3) Preparar tres copias sin eliminar aún nada\n",
    "SOIL_map_min  = SOIL_map.copy()\n",
    "SOIL_map_max  = SOIL_map.copy()\n",
    "SOIL_map_prom = SOIL_map.copy()\n",
    "\n",
    "sol_cols = [atri for atri in SOIL_map.columns if atri.startswith('SOL_K')]\n",
    "deep_cols = [atri for atri in SOIL_map.columns if atri.startswith('SOL_Z') and not atri.endswith('MX')]\n",
    "hydrogeological_observations = SOIL_map['Min'].notna()\n",
    "\n",
    "for idx, row in SOIL_map[hydrogeological_observations].iterrows():\n",
    "    vals = row[sol_cols]\n",
    "    deeps = row[deep_cols]\n",
    "    SOL_Z_MAPSWAT = deeps.sum()\n",
    "    SOL_K_MAPSWAT = SOL_Z_MAPSWAT/np.sum(deeps.values[deeps.values > 0] / vals.values[deeps.values > 0])\n",
    "    #print(SOL_K_MAPSWAT)\n",
    "    #print(vals.values)\n",
    "    #print(deeps.values[deeps.values > 0] / vals.values[deeps.values > 0])\n",
    "    r_min  = row['Min'] / SOL_K_MAPSWAT\n",
    "    r_max  = row['Max'] / SOL_K_MAPSWAT\n",
    "    r_prom = row['Prom'] / SOL_K_MAPSWAT\n",
    "    \n",
    "    SOIL_map_min.loc[idx, vals.index] = row[vals.index] * r_min\n",
    "    SOIL_map_max.loc[idx, vals.index] = row[vals.index] * r_max\n",
    "    SOIL_map_prom.loc[idx, vals.index] = row[vals.index] * r_prom\n",
    "    SOIL_map_min = SOIL_map_min.drop(columns = ['NAME','Min','Max','Prom'])\n",
    "    \n",
    "SOIL_map_max = SOIL_map_max.drop(columns = ['NAME','Min','Max','Prom'])\n",
    "SOIL_map_prom = SOIL_map_prom.drop(columns = ['NAME','Min','Max','Prom'])\n",
    "#print(SOIL_map_prom)\n",
    "SOIL_map_min.to_file(\"1.PRODUCTOS/SOIL_map_min_v2.shp\")\n",
    "SOIL_map_max.to_file(\"1.PRODUCTOS/SOIL_map_max_v2.shp\")\n",
    "SOIL_map_prom.to_file(\"1.PRODUCTOS/SOIL_map_prom_v2.shp\")\n",
    "\n",
    "SOIL_map_min_table  = SOIL_map_min.drop(columns='geometry')\n",
    "SOIL_map_max_table  = SOIL_map_max.drop(columns='geometry')\n",
    "SOIL_map_prom_table = SOIL_map_prom.drop(columns='geometry')\n",
    "\n",
    "SOIL_map_min_table.to_csv(\"1.PRODUCTOS/SOIL_map_min_v2.csv\", index=False)\n",
    "SOIL_map_max_table.to_csv(\"1.PRODUCTOS/SOIL_map_max_v2.csv\", index=False)\n",
    "SOIL_map_prom_table.to_csv(\"1.PRODUCTOS/SOIL_map_prom_v2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
